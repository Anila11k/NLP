{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5fc953c-6262-409f-b36f-4090f1487c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\acer\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\acer\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\acer\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\acer\\anaconda3\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\acer\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70fd36e0-1a3d-4795-a1fe-464b4e96dcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57827884-b69c-47d4-adb2-77a39e2d99b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a205616d-08b9-49ed-ab44-79b9a0e4bfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"Natural language processing is exciting! it has many applications,such as chatbots,translation,and more.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97b4d19f-7d56-45b2-b0ea-7cfc04fbe2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "747aaf56-ed39-47b0-9b54-f0a428ab3ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Tokenization:\n",
      "['Natural language processing is exciting!', 'it has many applications,such as chatbots,translation,and more.']\n"
     ]
    }
   ],
   "source": [
    "sentences=sent_tokenize(text)\n",
    "print(\"Sentence Tokenization:\")\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7636b65-256d-492d-a4c5-ccfe81b23fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word Tokenization:\n",
      "['Natural', 'language', 'processing', 'is', 'exciting', '!', 'it', 'has', 'many', 'applications', ',', 'such', 'as', 'chatbots', ',', 'translation', ',', 'and', 'more', '.']\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(text)\n",
    "print(\"\\nWord Tokenization:\")\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fba5aea3-f5be-438f-8229-1e42a9ae6d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "da702499-cce5-4287-a697-e40bbad3f57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another example \n",
    "# BASIC SENTENCE AND WORD TOKENIZATION\n",
    "# -------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3542770-c64b-42f8-ba2d-54bf21979aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60ec480b-1433-4bb5-8d3c-09bd300d2e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d70f20a8-f326-4fc5-a2e3-57e0cd20c01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"Hello! How are you? I'm doing great. let's learn NLP together.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bac8dd18-36de-403a-9aad-ea996562968f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentences: ['Hello!', 'How are you?', \"I'm doing great.\", \"let's learn NLP together.\"]\n"
     ]
    }
   ],
   "source": [
    "# sentence tokenization\n",
    "# ------------------------\n",
    "\n",
    "sentences = sent_tokenize(text)\n",
    "print(\"sentences:\",sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3dd08d6e-f42f-40a2-8e57-9185c06390e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words: ['Hello', '!', 'How', 'are', 'you', '?', 'I', \"'m\", 'doing', 'great', '.', 'let', \"'s\", 'learn', 'NLP', 'together', '.']\n"
     ]
    }
   ],
   "source": [
    "# word tokenization\n",
    "# -------------------\n",
    "\n",
    "words= word_tokenize(text)\n",
    "print(\"Words:\",words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2f8a27e2-d9ab-45fe-8f8a-bfbb9db35513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOKENIZING CSV OR TABULAR TEXT\n",
    "# -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "01b07109-7afc-421a-b4a8-95516d06b660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "42b95a82-d849-45a5-b089-96cb3ebdcce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dff0b7ce-dfa2-4cf8-82b7-7ccf727d2612",
   "metadata": {},
   "outputs": [],
   "source": [
    "text= \"Name,Age,country\\nAlice, 30, USA\\nBob, 25, UK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4a712782-cf3f-49a0-a203-caa9b28b0d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines= text.split('\\n')\n",
    "tokens=[word_tokenize(line)for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "70a63630-e5db-4f74-bdf6-848e301530aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Lines:\n",
      "['Name', ',', 'Age', ',', 'country']\n",
      "['Alice', ',', '30', ',', 'USA']\n",
      "['Bob', ',', '25', ',', 'UK']\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokenized Lines:\")\n",
    "for line_tokens in tokens:\n",
    "    print(line_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85308a45-693d-4bcf-82b4-cf80f3d1d4ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
